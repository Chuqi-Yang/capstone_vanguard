{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.utils import to_time_series\n",
    "import tslearn.metrics as tm\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Results_20160630_20200630.csv')\n",
    "df['LGCYINVESTORID'] = df['LGCYINVESTORID'].astype(str)\n",
    "df['INSTRID'] = df['INSTRID'].astype(str)\n",
    "df['HOLDDATE'] = df['HOLDDATE'].str.replace(r' 00:00:00', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('ListOfInvestor.csv')\n",
    "df_target['LgcyInvestorID'] = df_target['LgcyInvestorID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df[['LGCYINVESTORID', 'FULLNAME']].drop_duplicates()\n",
    "df_target_comp = pd.merge(df_target, df_comp, how='left', left_on='LgcyInvestorID', right_on='LGCYINVESTORID').drop(columns=['LgcyInvestorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quaters = set(df['HOLDDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series(comp_id):\n",
    "    res = defaultdict(list)\n",
    "    df_comp = df[df['LGCYINVESTORID']==comp_id]\n",
    "    data = pd.pivot_table(df_comp, index=['HOLDDATE'], columns=['INSTRID'], values=['PCTPORTFOLIO']).fillna(0)\n",
    "    \n",
    "    # missing check\n",
    "    quaters_investor = set(df_comp['HOLDDATE'])\n",
    "    for t in (quaters - quaters_investor):\n",
    "        data.loc[t] = 0\n",
    "    data = data.sort_index()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        res[col[1]] = data[col].to_list()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dict = defaultdict(dict)\n",
    "for i in range(len(df_target)):\n",
    "    comp_id = df_target['LgcyInvestorID'][i]\n",
    "    time_series_dict[comp_id] = get_time_series(comp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_sim(ts1, ts2):\n",
    "    sim = 0.0\n",
    "    commom_key = {key for key in ts1.keys() & ts2.keys() }\n",
    "    for key in commom_key:\n",
    "        sim += tm.dtw(ts1[key], ts2[key])\n",
    "    return 1.0/sim if sim != 0.0 else 0.0\n",
    "\n",
    "def get_ts_sim_2(ts1, ts2):\n",
    "    sim = 0.0\n",
    "    common_key = {key for key in ts1.keys() & ts2.keys() }\n",
    "    for key in common_key:\n",
    "        sim += tm.dtw(ts1[key], ts2[key])\n",
    "    for key in (ts1.keys() - common_key):\n",
    "        sim += tm.dtw(ts1[key], [0]*len(quaters))\n",
    "    return sim\n",
    "\n",
    "def get_similar_comp(target, time_series_dict):\n",
    "    res = defaultdict(float)\n",
    "    target_ts = time_series_dict[target]\n",
    "    for cp in (set(df_target['LgcyInvestorID']) - set([target])):\n",
    "        cp_ts = time_series_dict[cp]\n",
    "        sim = get_ts_sim_2(target_ts, cp_ts)\n",
    "        res[cp] = sim\n",
    "    res = pd.DataFrame(res.items())\n",
    "    res.columns = ['LgcyInvestorID', 'Distance']\n",
    "    res = res.sort_values(by=['Distance'], ascending=True).reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_target_comp)):\n",
    "    company = get_similar_comp(df_target_comp['LGCYINVESTORID'][i], time_series_dict)\n",
    "    company_res = pd.merge(company, df_comp, how='left', left_on='LgcyInvestorID', right_on='LGCYINVESTORID').drop(columns=['LgcyInvestorID'])\n",
    "    company_res.to_csv('./sim_res/'+df_target_comp['FULLNAME'][i]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanguard = get_similar_comp('2004260', time_series_dict)\n",
    "# vanguard_res = pd.merge(vanguard, df_comp, how='left', left_on='LgcyInvestorID', right_on='LGCYINVESTORID').drop(columns=['LgcyInvestorID'])\n",
    "# vanguard_res.to_csv('vangurad_time_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citadel = get_similar_comp('2006452', time_series_dict)\n",
    "# citadel_res = pd.merge(citadel, df_comp, how='left', left_on='LgcyInvestorID', right_on='LGCYINVESTORID').drop(columns=['LgcyInvestorID'])\n",
    "# citadel_res.to_csv('citadel_time_sim.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
