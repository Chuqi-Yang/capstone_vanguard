{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "top20pct_invStyle_similarity_matrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtccaylvk2d8",
        "outputId": "dc9746bd-4a98-4ab4-8739-2b10bb3d44b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVyE53fYlJ1n"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6hDaXjBlMk9"
      },
      "source": [
        "# read in 13F results\n",
        "file_name = '/content/gdrive/My Drive/capstone/full database/Results_20160630_20200630.csv'\n",
        "df = pd.read_csv(file_name)\n",
        "df['HOLDDATE'] = df['HOLDDATE'].str.replace(r' 00:00:00', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfmtXfhEFKF2"
      },
      "source": [
        "n_investors = df.LGCYINVESTORID.nunique()\n",
        "print('There are {} investors in 13F data.'.format(n_investors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdXuee6cLPw5"
      },
      "source": [
        "# read in list of investors of interest\n",
        "df_investors = pd.read_csv('/content/active_investor_list.csv')\n",
        "# df_investors = df_investors[df_investors.isActive==True]\n",
        "\n",
        "ls_investors = df_investors.LgcyInvestorId.to_list()\n",
        "print('There are {} investors which are we interested in.'.format(len(ls_investors)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crEmmtWV878t"
      },
      "source": [
        "active_ls_investors = df_investors[df_investors.isActive==True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1iP6aqDER5"
      },
      "source": [
        "# get those in predefined list\n",
        "df_sub = df.loc[df['LGCYINVESTORID'].isin(ls_investors),['INSTRID', 'COMNAME', 'LGCYINVESTORID', 'FULLNAME', 'HOLDDATE', 'SHSHLDVAL']]\n",
        "\n",
        "# calculate the sum of SHSHLDVAL for each investor in each quarter\n",
        "df_sub['SHSHLDVAL_Sum_ByQuarter'] = df_sub.groupby(['LGCYINVESTORID','HOLDDATE']).transform('sum').drop(['INSTRID', 'FULLNAME'], axis = 1)\n",
        "\n",
        "# calculate the (13F only) pct of the SHSHLDVAL of each instrument in its investor's sum of SHSHLDVAL for each quarter \n",
        "# (i.e. revised version of 'PCTPORTFOLIO', so that sum up to 1)\n",
        "df_sub['PCTPORTFOLIO_13F'] = df_sub['SHSHLDVAL'] / df_sub['SHSHLDVAL_Sum_ByQuarter']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwJ_5iURqcaF"
      },
      "source": [
        "sum(df_sub.drop_duplicates(subset=['INSTRID','COMNAME']).COMNAME.isna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTa3hP_4qfA0"
      },
      "source": [
        "df_sub.drop_duplicates(subset=['INSTRID','COMNAME'])[df_sub.drop_duplicates(subset=['INSTRID','COMNAME']).COMNAME.isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTnngG8opcyd"
      },
      "source": [
        "sum(df_sub.drop_duplicates(subset=['INSTRID','COMNAME']).COMNAME.isna())/len(df_sub.drop_duplicates(subset=['INSTRID','COMNAME']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98R_n1fZqRj1"
      },
      "source": [
        "df_sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xJ3Xqmyvse"
      },
      "source": [
        "vanguard_id = '2004260'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imUl0PfEbCu5"
      },
      "source": [
        "## Fill in missing time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiihdkTIcDEp"
      },
      "source": [
        "def fill_in_missing_date(df, dateColName, valColName):\n",
        "  '''\n",
        "  df: Column for investor id is 'LGCYINVESTORID' and column for instrumnet id is 'INSTRID'\n",
        "  dateColName: Fill in all the dates starting from the earlist to latest mentioned in this column\n",
        "  valColName: The column you want to fill in missing value.\n",
        "              The missing value will be filled as 0.\n",
        "\n",
        "  Return: a dataframe with filled missing value as 0 in valColName\n",
        "  '''\n",
        "  # create pivot table with id and date\n",
        "  df_pivot = pd.pivot_table(df,index='LGCYINVESTORID', columns= dateColName, values=valColName)\n",
        "  # fill in the missing value as 0. Each investor have data for all time stamp.\n",
        "  df_pivot.fillna(0,inplace=True)\n",
        "\n",
        "  # turn the pivot table to original format\n",
        "  df_stack = df_pivot.stack().reset_index()\n",
        "  df_stack.rename(columns = {0: valColName},inplace=True)\n",
        "  # map back the original df\n",
        "  df = pd.merge(df.drop(columns=valColName),df_stack,on = ['LGCYINVESTORID',dateColName])\n",
        "  return df_stack\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oet1zrfhKCLF"
      },
      "source": [
        "## Feature: Asset allocation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J83IvsaTNNyC"
      },
      "source": [
        "asset_aloc = pd.read_csv('/content/gdrive/My Drive/capstone/full database/AssetAllocWithDesc.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYF0L_IayxQv"
      },
      "source": [
        "asset_aloc[asset_aloc.LgcyInvestorId.isin(ls_investors)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXwWQc27qIO3"
      },
      "source": [
        "asset_aloc[asset_aloc.LgcyInvestorId.isin(ls_investors)]['TotAstAlloc'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkAXBwqgZVSX"
      },
      "source": [
        "asset_aloc['EqAstAlloc'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI7LnJAya10A"
      },
      "source": [
        "asset_aloc['TotAstAlloc'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXQQzdc9aUcV"
      },
      "source": [
        "asset_aloc[asset_aloc['TotAstAlloc'] == 'AARANGE1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljwzGtcuZimP"
      },
      "source": [
        "own2code = pd.read_excel('/content/gdrive/My Drive/capstone/full database/Own2Code.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9BnS_8xZsYw"
      },
      "source": [
        "own2code[own2code['Type_'] == 11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EY9y55Nex7"
      },
      "source": [
        "## Feature: pctportofolio with aggregated market cap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nvOXObmOlwt"
      },
      "source": [
        "mktcap = pd.read_csv('/content/gdrive/My Drive/capstone/full database/MktCap_MktCapSize_20160630_20200630.csv')\n",
        "mktcap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2q17kj6SKWj"
      },
      "source": [
        "merge = pd.merge(df_sub, mktcap, how='inner', left_on=['INSTRID', 'HOLDDATE'], right_on=['InstrId', 'EffectDate'])\n",
        "merge.drop(columns=['InstrId', 'EffectDate'])\n",
        "\n",
        "agg_mktcap_pivot = pd.pivot_table(merge,index = ['LGCYINVESTORID', 'HOLDDATE'], columns = ['MktCapSize'],values=['PCTPORTFOLIO_13F'],aggfunc=[np.sum],fill_value=0)\n",
        "\n",
        "investor_set = set(agg_mktcap_pivot.index.get_level_values('LGCYINVESTORID'))\n",
        "holddate_set = set(agg_mktcap_pivot.index.get_level_values('HOLDDATE'))\n",
        "\n",
        "mktcap_cat = ['PctLargeCap', 'MegaCap', 'MicroCap', 'MidCap', 'NanoCap', 'SmallCap']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-piRtH52k_P"
      },
      "source": [
        "mktcap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drkp7VSMw2aH"
      },
      "source": [
        "pd.merge(df_sub, mktcap,left_on=['INSTRID', 'HOLDDATE'], right_on=['InstrId', 'EffectDate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQpnElN9wpdj"
      },
      "source": [
        "agg_mktcap_pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5D7YeedTPvP"
      },
      "source": [
        "agg_mktcap_pivot.columns = mktcap_cat\n",
        "agg_mktcap_pivot = agg_mktcap_pivot.reset_index()\n",
        "for inv in investor_set:\n",
        "  holddates = set(agg_mktcap_pivot[agg_mktcap_pivot['LGCYINVESTORID']==inv]['HOLDDATE'].to_list())\n",
        "  if len(holddates) < len(holddate_set):\n",
        "    # print('Investor ID:', inv, ' missing:')\n",
        "    # print(holddate_set - holddates)\n",
        "    missing_dates = holddate_set - holddates\n",
        "    for md in missing_dates:\n",
        "      agg_mktcap_pivot = agg_mktcap_pivot.append([{'LGCYINVESTORID': inv, 'HOLDDATE':md}])\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz7QuOrQWn6M"
      },
      "source": [
        "agg_mktcap_pivot = agg_mktcap_pivot.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwSBom-1TWfZ"
      },
      "source": [
        "assert len(agg_mktcap_pivot) == len(investor_set) * len(holddate_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAbAjfLnT05j"
      },
      "source": [
        "agg_mktcap_pivot = agg_mktcap_pivot.set_index(['LGCYINVESTORID','HOLDDATE']).stack().reset_index()\n",
        "agg_mktcap_pivot = agg_mktcap_pivot.rename(columns={agg_mktcap_pivot.columns[-2]:'MktCap',agg_mktcap_pivot.columns[-1]:'PCTPORTFOLIO_13F'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqPxzjNMY4Oi"
      },
      "source": [
        "agg_mktcap_pivot.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNvVa2cXy7W"
      },
      "source": [
        "agg_mktcap_pivot = agg_mktcap_pivot.pivot_table(index=['LGCYINVESTORID'],columns=['HOLDDATE', 'MktCap'],values=['PCTPORTFOLIO_13F'])\n",
        "agg_mktcap_pivot.columns =  agg_mktcap_pivot.columns.droplevel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYcCmz1O7P0j"
      },
      "source": [
        "## Feature: Turnover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp7-kEG57NCx"
      },
      "source": [
        "# read in turnover rate\n",
        "turnover = pd.read_csv('/content/gdrive/My Drive/capstone/full database/Own2InvHldTO.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4luxk1Ln8SyX"
      },
      "source": [
        "# select these in a list\n",
        "turnover = turnover[turnover.LgcyInvestorId.isin(ls_investors) & (turnover.CalcBasisCode==2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfyzlBMp8OT_"
      },
      "source": [
        "# fill in 0 for missing date\n",
        "turnover_pivot = turnover.pivot_table(index='LgcyInvestorId', columns='EffectToDate',values='OwnTurnover').fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDAcUWtiA6oc"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "# create distance matrix for gephi \n",
        "turnover_matrix = pd.DataFrame(euclidean_distances(turnover_pivot),index = turnover_pivot.index, columns=turnover_pivot.index)\n",
        "# turnover_matrix.to_csv('/content/gdrive/My Drive/capstone/distance matrix/turnover_distance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr87pV7JlVOf"
      },
      "source": [
        "## Feature: Top 20% pct\n",
        "\n",
        "Definition: the porportion of investment on top 20% of instruments.\n",
        "This represents the concentration of the investment. In other words, if this score is low, the investor prefers  distributed investment. Otherwise, the investor prefers concentrated investment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6vV4vCNZWax"
      },
      "source": [
        "### Create features for the listed investors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vep4KyKCl_4W"
      },
      "source": [
        "def topPct(df, pct=0.2 ,k=10):\n",
        "  n = len(df)\n",
        "  k = int(pct * n)\n",
        "  if k == 0:\n",
        "    k = 1\n",
        "  return sum(sorted(df)[-k:])/sum(df)\n",
        "\n",
        "df_toppct = df_sub.groupby(['LGCYINVESTORID','FULLNAME','HOLDDATE']).agg({'SHSHLDVAL': topPct}).reset_index()\n",
        "\n",
        "df_toppct.rename(columns={'SHSHLDVAL':'TOP20%SHSHLDVALpct'},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeXQj_0FmDBz"
      },
      "source": [
        "df_toppct.LGCYINVESTORID.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHHJOalYV8PD"
      },
      "source": [
        "df_toppct = fill_in_missing_date(df_toppct, 'HOLDDATE', 'TOP20%SHSHLDVALpct')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKmuFdpmG59"
      },
      "source": [
        "# df_toppct.to_csv('/content/gdrive/My Drive/capstone/full database/TOP20%SHSHLDVALpct_20160630_20200630.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3jfUcAjZfND"
      },
      "source": [
        "### Compute Euclidean distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiEvUD3GX0Rp"
      },
      "source": [
        "concentration_pivot = df_toppct.pivot_table(index='LGCYINVESTORID', columns='HOLDDATE',values='TOP20%SHSHLDVALpct').fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xxB8cbY8Dl"
      },
      "source": [
        "# create distance matrix for listed investor\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "concentration_matrix = pd.DataFrame(euclidean_distances(concentration_pivot),index =concentration_pivot.index,columns=concentration_pivot.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFOHSByZhXj"
      },
      "source": [
        "# concentration_matrix.to_csv('conventration_distance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjarw0qcsFmk"
      },
      "source": [
        "## Feature: investment style, Industry, market of Investors' contacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blf3AdqrsnyR"
      },
      "source": [
        "### Get description of different specialized code\n",
        "\n",
        "We need to map with Own2Code(Type_=13) to get the description of the SpecCode.\n",
        "SpecCat:\n",
        "  - SpecCap == 1: Industry\n",
        "    - Code in Own2Code: IS (201 different)\n",
        "    - Code in data: xx\n",
        "    - **Problem: IS193,IS194,IS195,IS196**\n",
        "  - SpecCap == 3: Market Capitalization range in which the Investor Contact specializes\n",
        "    - Code in Own2Code: MCS1 - MCS4\n",
        "    - Code in data: 224 225 226 227\n",
        "  - SpecCap == 4: Investment Style \n",
        "    - Code in Own2Code: ISS1 - ISS20(ISS19 not exists)\n",
        "    - Code in data: 201 - 220 \n",
        "    - **Problem: ISS19 not exists**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SLBFjnvsnJ5"
      },
      "source": [
        "# read in contacts info for investors in 13F\n",
        "contact_info = '/content/gdrive/My Drive/capstone/full database/ContactResults.csv'\n",
        "contact_df = pd.read_csv(contact_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2zrvUFmwYKA"
      },
      "source": [
        "contact_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KvbdQwZtYo9"
      },
      "source": [
        "# read in code table\n",
        "code_file_name = '/content/gdrive/My Drive/capstone/full database/Own2Code.xlsx'\n",
        "code_df = pd.read_excel(code_file_name)\n",
        "code_df = code_df.fillna('9999999')\n",
        "spec_code_df = code_df[code_df.Type_ == 13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANgNfJuCskdz"
      },
      "source": [
        "def explanation_spec(SpecCat, SpecCode):\n",
        "  if pd.isna(SpecCat) or pd.isna(SpecCode):\n",
        "    return \n",
        "  SpecCode = int(SpecCode)\n",
        "  try:\n",
        "    if SpecCat == 1:\n",
        "      return 'Industry_' + spec_code_df[spec_code_df.Code == ('IS'+str(SpecCode))] ['Desc_'].values[0]\n",
        "    elif SpecCat == 3:\n",
        "      return 'Market_' + spec_code_df[spec_code_df.Code == ('MCS'+str(SpecCode-223))]['Desc_'].values[0]\n",
        "    elif SpecCat == 4:\n",
        "      return 'InvStyle_' + spec_code_df[spec_code_df.Code == ('ISS'+str(SpecCode-200))]['Desc_'].values[0]\n",
        "  except:\n",
        "    No_explanation.append((SpecCat, SpecCode))\n",
        "    return 'No_explanation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqdcJbHXvvqW"
      },
      "source": [
        "No_explanation = []\n",
        "contact_df['SpecDesc_'] = contact_df.apply(lambda x: explanation_spec(x.SpecCat, x.SpecCode), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i36fyGyizjqZ"
      },
      "source": [
        "# part of specCat don't have specDesc_\n",
        "from collections import Counter\n",
        "Counter(No_explanation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir-lObITF-qS"
      },
      "source": [
        "# Remove those with no explanation\n",
        "contact_df = contact_df[contact_df['SpecDesc_'] != 'No_explanation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TS3KT5q6Uzy"
      },
      "source": [
        "### Aggregate for each investor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foN3tA8334C5"
      },
      "source": [
        "investor_style = pd.pivot_table(contact_df,index=['LgcyInvestorId'],columns=['SpecCat','SpecDesc_'], values=['LgcyPersonId'],aggfunc='count')\n",
        "# investor_style.fillna(0,inplace=True)\n",
        "investor_style.columns = investor_style.columns.droplevel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7chYlm_5zvC"
      },
      "source": [
        "print('{}({}) investors in 13F have contact info.'.format(len(investor_style), len(investor_style)/n_investors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B7jMtnw_gGu"
      },
      "source": [
        "# contact_df.groupby(['LgcyInvestorId','SpecCat','SpecDesc_']).agg({'LgcyPersonId':'count'}).reset_index().to_csv('investstyle.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLD4lt4KJTqJ"
      },
      "source": [
        "### Create features for the listed investors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3VlvupMJSqH"
      },
      "source": [
        "investor_style_sub = investor_style[investor_style.index.isin(ls_investors)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ygrDsByYfA"
      },
      "source": [
        "# whether we need to do td-idf\n",
        "investor_style_sub[4].sum(axis=0).hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K8jJfLGyYfD"
      },
      "source": [
        "investor_style_sub[4].sum(axis=0).sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23d-2ZhJdKk6"
      },
      "source": [
        "# compute weight, use idf\n",
        "industry_weight = np.log(len(investor_style_sub) / (investor_style_sub[1].count(axis=0) + 1))\n",
        "invStyle_weight = np.log(len(investor_style_sub) / (investor_style_sub[4].count(axis=0) + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItgXfIngEeYO"
      },
      "source": [
        "# normalize\n",
        "def normalize(df):\n",
        "  return df.div(df.sum(axis=1),axis=0).fillna(0)\n",
        "\n",
        "industry_sub = normalize(investor_style_sub[1])\n",
        "invStyle_sub = normalize(investor_style_sub[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OAEKk8q-3m1"
      },
      "source": [
        "industry_sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-EFab3IdZkn"
      },
      "source": [
        "# compute distance \n",
        "invStyle_matrix = pd.DataFrame(euclidean_distances(industry_sub),index =industry_sub.index,columns=industry_sub.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5WdC2n0dZks"
      },
      "source": [
        "# invStyle_matrix.to_csv('invStyle_distance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz0JuHVZAGAl"
      },
      "source": [
        "## Feature: Number of instruments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eidEoOrgAFfs"
      },
      "source": [
        "n_instruments = df_sub.groupby(['LGCYINVESTORID','HOLDDATE']).agg({'INSTRID':'count'}).reset_index()\n",
        "n_instruments_pivot = pd.pivot_table(n_instruments,index=['LGCYINVESTORID'],columns=['HOLDDATE'],values=['INSTRID']).fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z85G_dvtBEAR"
      },
      "source": [
        "n_instruments_pivot.columns = n_instruments_pivot.columns.droplevel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWQl67ruBKsx"
      },
      "source": [
        "n_instruments_pivot_static = n_instruments.groupby('LGCYINVESTORID').agg({'INSTRID':'max'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_StYAyB40r"
      },
      "source": [
        "## Feature: Total Asset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkswREMYEZqm"
      },
      "source": [
        "total_asset = df_sub.groupby(['LGCYINVESTORID','HOLDDATE']).agg({'SHSHLDVAL_Sum_ByQuarter':'max'}).reset_index()\n",
        "n_instruments_pivot = pd.pivot_table(df_sub,index=['LGCYINVESTORID'],columns=['SHSHLDVAL_Sum_ByQuarter'],values=['INSTRID']).fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmydxsrjE7oD"
      },
      "source": [
        "total_asset = df_sub.groupby(['LGCYINVESTORID','HOLDDATE']).agg({'SHSHLDVAL_Sum_ByQuarter':'max'}).reset_index()\n",
        "total_asset_pivot = pd.pivot_table(total_asset,index=['LGCYINVESTORID'],columns=['HOLDDATE'],values=['SHSHLDVAL_Sum_ByQuarter']).fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JavBmtYwQ_cz"
      },
      "source": [
        "total_asset_pivot.columns = total_asset_pivot.columns.droplevel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq-IRQ1aRRPm"
      },
      "source": [
        "total_asset_pivot_static = total_asset.groupby('LGCYINVESTORID').agg({'SHSHLDVAL_Sum_ByQuarter':'max'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8H7QLvihujU"
      },
      "source": [
        "## K_means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBs6yywpQQnW"
      },
      "source": [
        "agg_mktcap_pivot.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVJx_WRFiGjH"
      },
      "source": [
        "# one company no turnover\n",
        "turnover_pivot.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7_Bl3KEh4qA"
      },
      "source": [
        "concentration_pivot.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W92cv1Vvivhb"
      },
      "source": [
        "industry_sub.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuSkWo3eDPYY"
      },
      "source": [
        "# normalize turnover_pivot\n",
        "max_turnover = turnover_pivot.max().max()\n",
        "turnover_pivot_standard = turnover_pivot/max_turnover"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJ25WKNRmrh"
      },
      "source": [
        "# normalize number of instruments\n",
        "max_n_instruments = n_instruments_pivot.max().max()\n",
        "n_instruments_pivot_standard = n_instruments_pivot/max_n_instruments\n",
        "n_instruments_pivot_static_standard = n_instruments_pivot_static/max_n_instruments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RludcKLlSFc9"
      },
      "source": [
        "# normalize total asset\n",
        "max_total_asset = total_asset_pivot.max().max()\n",
        "total_asset_pivot_standard = total_asset_pivot/max_total_asset\n",
        "total_asset_pivot_static_standard = total_asset_pivot_static/max_total_asset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSmn5yw6i22I"
      },
      "source": [
        "X = pd.concat([agg_mktcap_pivot,\n",
        "               turnover_pivot_standard, \n",
        "               n_instruments_pivot_static_standard,\n",
        "               total_asset_pivot_static_standard,\n",
        "               concentration_pivot,invStyle_sub], axis=1).fillna(0)\n",
        "              \n",
        "X_sub = X[X.index.isin(active_ls_investors.LgcyInvestorId)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaFtQH8BTPGu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwhl7BphETjx"
      },
      "source": [
        "draw_tsne(X_sub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdMNy3dJkhy4"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def fit_kmeans(n_components,X):\n",
        "    km = KMeans(n_components)\n",
        "    km.fit(X)\n",
        "    predictions = km.predict(X)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRkXNtCppiAd"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def draw_tsne(X, predictions=None):\n",
        "    tsne = TSNE(n_components=2)\n",
        "    x = tsne.fit_transform(X)\n",
        "    if predictions is None:\n",
        "      plt.scatter(x[:,0],x[:,1])\n",
        "      plt.title('pctportfolio clustering')\n",
        "    else:\n",
        "      plt.scatter(x[:,0],x[:,1],c=predictions)\n",
        "      plt.title('pctportfolio clustering')      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0d2ZKGs_wJK"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "def InternalEvaluation(data, clusters):\n",
        "    scores = {}\n",
        "    \"\"\"\n",
        "    The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. \n",
        "    Scores around zero indicate overlapping clusters.\n",
        "    The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\n",
        "    \"\"\"\n",
        "    scores['_silhouette_score'] =metrics.silhouette_score(data,clusters ,metric='euclidean')\n",
        "    \"\"\"\n",
        "    The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\n",
        "    The score is fast to compute\n",
        "    \"\"\"\n",
        "    scores['_calinski_harabaz_score'] = metrics.calinski_harabasz_score(data,clusters)\n",
        "    \"\"\"\n",
        "    Zero is the lowest possible score. Values closer to zero indicate a better partition.\n",
        "    The Davies-Boulding index is generally higher for convex clusters than other concepts of clusters, \n",
        "    such as density based clusters like those obtained from DBSCAN.\n",
        "    \"\"\"\n",
        "    scores['_davies_bouldin_score'] = metrics.davies_bouldin_score(data,clusters)\n",
        "    return scores\n",
        "\n",
        "def draw_scores(scores, start_k=2):\n",
        "  score_type = list(scores[0].keys())\n",
        "  n_type = len(score_type)\n",
        "  plt.figure(figsize=(8,4))\n",
        "  for i in range(n_type):\n",
        "    sc_type = score_type[i]\n",
        "    score = [sc[sc_type] for sc in scores]\n",
        "    plt.subplot(1, n_type, i+1)\n",
        "    plt.plot(range(start_k,len(score) + start_k ), score)\n",
        "    plt.title(' '.join(sc_type.split('_')).title())\n",
        "    plt.xlabel('k')\n",
        "  plt.suptitle('Metrics for Clustering')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_jQLZmpptf1"
      },
      "source": [
        "def modeling(X):\n",
        "  scores = []\n",
        "  for k in range(2, 10):\n",
        "    predictions = fit_kmeans(k,X)\n",
        "    score = InternalEvaluation(X, predictions)\n",
        "    scores.append(score)\n",
        "  plt.figure(1)\n",
        "  draw_scores(scores)\n",
        "  plt.figure(2)\n",
        "  # draw_tsne(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELkw1GpA9SB"
      },
      "source": [
        "agg_mktcap_pivot,\n",
        "              #  turnover_pivot, \n",
        "               concentration_pivot,invStyle_sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH-Ezl_TA4Do"
      },
      "source": [
        "modeling(X_sub)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTlh0rdzAXLV"
      },
      "source": [
        "predictions = fit_kmeans(3,X_sub)\n",
        "draw_tsne(X_sub,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd7GT96vARnU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}